{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHEMDNER Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import punkt\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Paths to raw files provided by the dataset; Do NOT modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_TRAINING_TEXT = './chemdner_corpus/training.abstracts.txt'\n",
    "FILE_TRAINING_LBL = './chemdner_corpus/training.annotations.txt'\n",
    "\n",
    "FILE_DEV_TEXT = './chemdner_corpus/development.abstracts.txt'\n",
    "FILE_DEV_LBL = './chemdner_corpus/development.annotations.txt'\n",
    "\n",
    "FILE_EVAL_TEXT = './chemdner_corpus/evaluation.abstracts.txt'\n",
    "FILE_EVAL_LBL = './chemdner_corpus/evaluation.annotations.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A string of all the raw texts in the CHEMDNER dataset, used to train the NLTK tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loading the Abstracts into a dictionary `{id: [title, abstract]}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_abstracts(file: str) -> dict:\n",
    "    global all_texts\n",
    "    with open(file, 'r') as f:\n",
    "        ret = dict()\n",
    "        for line in f:\n",
    "            if line[-1] == '\\n':\n",
    "                line = line[:-1]  # removing the EOL character\n",
    "            line_list = line.split('\\t')\n",
    "            assert len(line_list) == 3, f\"ERROR1: This line dose not have 3 columns:\\nFILE: {file}\\n{line_list}\"\n",
    "            all_texts = all_texts + line_list[1] + ' ' + line_list[2] + ' '\n",
    "            ret[line_list[0]] = line_list\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "# of sentences read: Train: 3500, Dev: 3500, Eval: 3000\n"
     ]
    }
   ],
   "source": [
    "train_txt = read_abstracts(FILE_TRAINING_TEXT)\n",
    "dev_txt = read_abstracts(FILE_DEV_TEXT)\n",
    "eval_txt = read_abstracts(FILE_EVAL_TEXT)\n",
    "print(f\"Done!\\n# of sentences read: Train: {len(train_txt)}, Dev: {len(dev_txt)}, Eval: {len(eval_txt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read the annotations and group them by Artical Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def read_annotations(file: str) -> dict:\n",
    "    with open(file, 'r') as f:\n",
    "        ret = dict()\n",
    "        for line in f:\n",
    "            if line[-1] == '\\n':\n",
    "                line = line[:-1]  # removing EOL\n",
    "            line_list = line.split('\\t')\n",
    "            assert len(line_list) == 6, f\"ERROR2: This line dose not have 6 columns:\\n{line_list}\"\n",
    "            line_list[2] = int(line_list[2])\n",
    "            line_list[3] = int(line_list[3])\n",
    "            if line_list[0] not in ret:\n",
    "                ret[line_list[0]] = {'T': list(), 'A': list()}\n",
    "            ret[line_list[0]][line_list[1]].append(line_list)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_anno = read_annotations(FILE_TRAINING_LBL)\n",
    "dev_anno = read_annotations(FILE_DEV_LBL)\n",
    "eval_anno = read_annotations(FILE_EVAL_LBL)\n",
    "print(f\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train NLTK tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "punkt_tokenizer = punkt.PunktSentenceTokenizer(all_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_labels(sentence: str, anno_list:list) -> list:\n",
    "    anno_list.sort(key = lambda x:x[2])\n",
    "    last_pos = 0\n",
    "    sentence_lst = list()\n",
    "    label_lst = list()\n",
    "    for item in anno_list:\n",
    "        start_pos = item[2]\n",
    "        end_pos = item[3]\n",
    "        part = word_tokenize(sentence[last_pos:start_pos])\n",
    "        sentence_lst.extend(part)\n",
    "        label_lst.extend([('O', '')] * len(part))\n",
    "        part = word_tokenize(sentence[start_pos:end_pos])\n",
    "        sentence_lst.extend(part)\n",
    "        label_lst.extend([('B', item[5])] + [('I', item[5])] * (len(part)-1))\n",
    "        last_pos = end_pos\n",
    "    part = word_tokenize(sentence[last_pos:])\n",
    "    sentence_lst.extend(part)\n",
    "    label_lst.extend([('O', '')] * len(part))\n",
    "    assert len(sentence_lst) == len(label_lst), f\"ERROR3: Label and tokenized sentence length mismatch!\\n\" \\\n",
    "                    f\"{sentence}\\n{list(itertools.zip_longest(sentence_lst, label_lst))}\\n{anno_list}\"\n",
    "    return (sentence_lst, label_lst)\n",
    "    \n",
    "def get_labels(text: dict, annotations: dict):\n",
    "    sentence_lst = list()\n",
    "    label_lst = list()\n",
    "    for pmid in annotations:\n",
    "        dct = annotations[pmid]\n",
    "        if dct['T']:\n",
    "            sentence = text[pmid][1]\n",
    "            anno_list = dct['T']\n",
    "            lst1, lst2 = _generate_labels(sentence, anno_list)\n",
    "            sentence_lst.append(lst1)\n",
    "            label_lst.append(lst2)\n",
    "        if dct['A']:\n",
    "            full_abstract = text[pmid][2]\n",
    "            sentences = punkt_tokenizer.tokenize(full_abstract)\n",
    "            anno_list = dct['A']\n",
    "            anno_list.sort(key=lambda x:x[2])\n",
    "            for sentence in sentences:\n",
    "                sentence_offset_in_abstract = full_abstract.find(sentence)\n",
    "                anno_list_for_this_sentence = list()\n",
    "                if anno_list:\n",
    "                    next_start_pos = anno_list[0][2]                    \n",
    "                    while next_start_pos < sentence_offset_in_abstract + len(sentence):\n",
    "                        tmp_anno = anno_list[0]\n",
    "                        del anno_list[0]\n",
    "                        tmp_anno[2] = tmp_anno[2] - sentence_offset_in_abstract\n",
    "                        tmp_anno[3] = tmp_anno[3] - sentence_offset_in_abstract\n",
    "                        anno_list_for_this_sentence.append(tmp_anno)\n",
    "                        if anno_list:\n",
    "                            next_start_pos = anno_list[0][2]\n",
    "                        else:\n",
    "                            break\n",
    "                lst1, lst2 = _generate_labels(sentence, anno_list_for_this_sentence)\n",
    "                sentence_lst.append(lst1)\n",
    "                label_lst.append(lst2)\n",
    "    return (sentence_lst, label_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized_txt, train_label = get_labels(train_txt, train_anno)\n",
    "dev_tokenized_txt, dev_label = get_labels(dev_txt, dev_anno)\n",
    "eval_tokenized_txt, eval_label = get_labels(eval_txt, eval_anno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the generated label of a random training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B', 'ABBREVIATION'), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', ''), ('O', '')]\n"
     ]
    }
   ],
   "source": [
    "print(train_label[8754])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the tokens and the labels together to make sure the labels are correctly assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PBDE', ('B', 'ABBREVIATION')), ('-mediated', ('O', '')), ('MD', ('O', '')), ('per', ('O', '')), ('se', ('O', '')), ('or', ('O', '')), ('enhanced', ('O', '')), ('by', ('O', '')), ('a', ('O', '')), ('background', ('O', '')), ('that', ('O', '')), ('confers', ('O', '')), ('susceptibility', ('O', '')), ('to', ('O', '')), ('this', ('O', '')), ('exposure', ('O', '')), ('may', ('O', '')), ('have', ('O', '')), ('profound', ('O', '')), ('implications', ('O', '')), ('in', ('O', '')), ('the', ('O', '')), ('energy', ('O', '')), ('balance', ('O', '')), ('of', ('O', '')), ('brain', ('O', '')), ('.', ('O', ''))]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(train_tokenized_txt[8754], train_label[8754])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Determine the max length of a sentence that is allowed in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lengths = np.array([len(x) for x in train_tokenized_txt])\n",
    "dev_lengths = np.array([len(x) for x in dev_tokenized_txt])\n",
    "eval_lengths = np.array([len(x) for x in eval_tokenized_txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24732 24799 21167\n",
      "69.0 70.0 69.34000000000015\n",
      "60.38000000000102 60.0 61.0\n"
     ]
    }
   ],
   "source": [
    "print(len(train_lengths), len(dev_lengths), len(eval_lengths))\n",
    "print(np.percentile(train_lengths,  99), np.percentile(dev_lengths,  99), np.percentile(eval_lengths,  99))\n",
    "print(np.percentile(train_lengths,  98), np.percentile(dev_lengths,  98), np.percentile(eval_lengths,  98))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results of above three code blocks, we can see that if the maximum allowed length of a sentence is set to 75,  only less than 1% will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_2D(pylist: list, max_len: int, padding_val):\n",
    "    for row in pylist:\n",
    "        if len(row) < max_len:\n",
    "            row += [padding_val for _ in range(max_len - len(row))]\n",
    "        else:\n",
    "            row = row[:max_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_2D(train_tokenized_txt, max_len, '')\n",
    "padding_2D(dev_tokenized_txt, max_len, '')\n",
    "padding_2D(eval_tokenized_txt, max_len, '')\n",
    "padding_2D(train_label, max_len, ('P', ''))\n",
    "padding_2D(dev_label, max_len, ('P', ''))\n",
    "padding_2D(eval_label, max_len, ('P', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pickle(obj, file):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(train_tokenized_txt, './x_train.pickle')\n",
    "save_to_pickle(dev_tokenized_txt, './x_dev.pickle')\n",
    "save_to_pickle(eval_tokenized_txt, './x_eval.pickle')\n",
    "save_to_pickle(train_label, './y_train.pickle')\n",
    "save_to_pickle(dev_label, './y_dev.pickle')\n",
    "save_to_pickle(eval_label, './y_eval.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
